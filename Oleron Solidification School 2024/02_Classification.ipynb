{"cells":[{"cell_type":"markdown","id":"3f357242-9dd7-4df5-a3f9-004989b233da","metadata":{"id":"3f357242-9dd7-4df5-a3f9-004989b233da"},"source":["# Hands-on 2: Classification"]},{"cell_type":"markdown","source":["## Preparation\n","\n","*Before we start the pratical section, we will take the time to import some libraries, define some colours for our plots and create some functions to generate artificial data. Dont worry too much about this first steps.*"],"metadata":{"id":"Lnt-EmuOBFWP"},"id":"Lnt-EmuOBFWP"},{"cell_type":"code","execution_count":null,"id":"d5b0d9cb-6834-41fb-bd56-0a66d98a82f6","metadata":{"tags":[],"id":"d5b0d9cb-6834-41fb-bd56-0a66d98a82f6"},"outputs":[],"source":["# Basic inputs\n","import numpy as np\n","from numpy import mean\n","from numpy import std\n","\n","from scipy import linalg\n","from scipy import stats\n","\n","# Drawing modules\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","from matplotlib import colors\n","from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n","from matplotlib.collections import PatchCollection\n","from matplotlib.patches import Rectangle\n","from matplotlib.patches import Ellipse\n","\n","# Utilities\n","from operator import itemgetter\n","\n","# Import some tools from Scikit-Learn\n","# Metrix\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score\n","\n","# Inspection tools\n","from sklearn.inspection import DecisionBoundaryDisplay\n","\n","# Create color maps\n","cmap_light_b = ListedColormap([\"#FFAAAA\", \"#AAFFAA\", \"#AAAAFF\"])\n","cmap_light = ListedColormap([\"#FFAAAA\", \"#AAAAFF\", \"#AAFFAA\"])\n","#cmap_light = ListedColormap(['red', 'blue', 'green'])\n","cmap_bold = ListedColormap([\"#FF0000\", \"#0000FF\", \"#00FF00\"])\n","\n","my_cmap= ListedColormap(['#ff3d3d', '#3d3dff', '#2dc22d', '#fcea19'])\n","\n","colors = [\"red\",\"blue\"]\n","cmap1 = LinearSegmentedColormap.from_list(\"mycmap\", colors)\n","\n","# Create color dictionary for classes\n","color_class = { 0 : 'red'\n","               ,1 : 'blue'\n","               ,2 : 'green'\n","               ,3 : 'yellow'\n","            }"]},{"cell_type":"code","execution_count":null,"id":"4b4ea454-c676-4e10-b9f8-2a9c0d688633","metadata":{"tags":[],"id":"4b4ea454-c676-4e10-b9f8-2a9c0d688633"},"outputs":[],"source":["# Data creation : Gaussian samples with fixed covariances\n","# a bit misterious but not too much\n","\n","def dataset_fixed_cov(n=300,dim=2):\n","    \"\"\"Generate 2 Gaussians samples with the same covariance matrix\"\"\"\n","    #n, dim = 300, 2\n","    np.random.seed(0)\n","    # centers\n","    C = np.array([[0.0, -0.23], [0.83, 0.23]])\n","    X = np.r_[\n","        np.dot(np.random.randn(n, dim), C),\n","        np.dot(np.random.randn(n, dim), C) + np.array([1, 1]),\n","    ]\n","    y = np.hstack((np.zeros(n), np.ones(n)))\n","    return X, y\n","\n","\n","def dataset_cov():\n","    \"\"\"Generate 2 Gaussians samples with different covariance matrices\"\"\"\n","    n, dim = 300, 2\n","    np.random.seed(0)\n","    C = np.array([[0.0, -1.0], [2.5, 0.7]]) * 2.0\n","    X = np.r_[\n","        np.dot(np.random.randn(n, dim), C),\n","        np.dot(np.random.randn(n, dim), C.T) + np.array([1, 4]),\n","    ]\n","    y = np.hstack((np.zeros(n), np.ones(n)))\n","    return X, y\n","\n","def Test_model_accuracy(y_pred, y_test):\n","\n","    dif =  (y_pred - y_test)==0\n","    count=np.unique(dif, return_counts=True)\n","\n","    accuracy = count[1][1]/len(y_test)\n","    print ('Accuracy (direct calculation): ', accuracy)\n","\n","    Conf_Mat = confusion_matrix(y_test, y_pred)\n","    tn, fp, fn, tp = Conf_Mat.ravel()\n","\n","    print('True positive: ', tp)\n","    print('True negative: ', tn)\n","    print('False positive: ', fp)\n","    print('False negative: ', fn)\n","\n","    print ('Accuracy (Conf. Matrix): ', (tp+tn)/(tp+tn+fp+fn))\n","    prec = tp/(tp+fp)\n","    print ('Precision (Conf. Matrix): ', prec)\n","    rec = tp/(tp+fn)\n","    print ('Recall (Conf. Matrix): ', rec)\n","    f1s = 2*(rec*prec/(rec+prec))\n","    print ('F1-score (Conf. Matrix): ', f1s)\n","    print ('F1-score (skl metrics): ', f1_score(y_test, y_pred))\n"]},{"cell_type":"markdown","id":"0c0fd8ef-b949-4bbf-8c1e-e1656b3dc0cd","metadata":{"id":"0c0fd8ef-b949-4bbf-8c1e-e1656b3dc0cd"},"source":["## A first contact with the problem - Classification with Linear Discriminant Analysis\n","\n","Here, we start by using a function (`dataset_fixed_cov`) to colect our artificial data. Try to print and check the shape of `X` and `y`."]},{"cell_type":"code","execution_count":null,"id":"d18ec38e-479b-4fab-9b2a-3d2505908597","metadata":{"id":"d18ec38e-479b-4fab-9b2a-3d2505908597"},"outputs":[],"source":["# Create or load the data\n","N_sample = 300\n","N_dim =2\n","\n","X,y = dataset_fixed_cov(N_sample,N_dim)"]},{"cell_type":"markdown","id":"9e63dee1-6f54-40e6-ad80-50ce7d1065a9","metadata":{"id":"9e63dee1-6f54-40e6-ad80-50ce7d1065a9"},"source":["Even more helpful in the case of 2D data, lets also plot this data and try to understand what it is. Here, the plot at the left is just a scatter plot of the data points. In the right, we recolour the same plot with the classes labelled in `y`."]},{"cell_type":"code","execution_count":null,"id":"1d47d778-330a-435b-acd1-79c40e0e83a4","metadata":{"id":"1d47d778-330a-435b-acd1-79c40e0e83a4"},"outputs":[],"source":["Figure, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14,5))\n","ax1.scatter(X[:,0],X[:,1])\n","ax1.set_xlabel(r'$x_1$',fontsize = 16)\n","ax1.set_ylabel(r'$x_2$',fontsize = 16)\n","\n","X0_s, X1_s = X[y == 0], X[y == 1]\n","ax2.scatter(X0_s[:,0],X0_s[:,1], marker = 'o', color = color_class[0], alpha=0.5, label='Class 0')\n","ax2.scatter(X1_s[:,0],X1_s[:,1], marker = '^', color = color_class[1], alpha=0.5, label='Class 1')\n","ax2.set_xlabel(r'$x_1$',fontsize = 16)\n","ax2.set_ylabel(r'$x_2$',fontsize = 16)\n","ax2.legend(loc='best',fontsize = 16)\n","\n","Figure.show()"]},{"cell_type":"markdown","id":"3d9f724b-abab-4865-bf5d-91e6576e33d7","metadata":{"id":"3d9f724b-abab-4865-bf5d-91e6576e33d7"},"source":["### Train-test split\n","\n","What we will do in the next sections is to train models capable to classify points as pertencing to one of those two classes. To do so, we will separate a test set from the data that will be used in the training."]},{"cell_type":"code","execution_count":null,"id":"0a6f831f-2c37-412c-9171-2d911b331425","metadata":{"id":"0a6f831f-2c37-412c-9171-2d911b331425"},"outputs":[],"source":["# Here we use now the train test split of Scikit-learn\n","from sklearn.model_selection import train_test_split\n","\n","# Define a random state for reproducibility during the different use and methods\n","random_state = 1234\n","\n","# split the dataset into a train set and a test set : usually 80% of the data in the training\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=random_state)"]},{"cell_type":"markdown","id":"bacc1890-5fb0-4260-861a-eb1a9d899793","metadata":{"tags":[],"id":"bacc1890-5fb0-4260-861a-eb1a9d899793"},"source":["### Visualize the train and test with the classes"]},{"cell_type":"code","execution_count":null,"id":"ac7a1541-3c97-4705-a2b4-cb185aa984ec","metadata":{"id":"ac7a1541-3c97-4705-a2b4-cb185aa984ec"},"outputs":[],"source":["Figure, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14,5))\n","ax1.scatter(X[:,0],X[:,1], marker = 'o', s = 30)\n","ax1.scatter(X_train[:,0],X_train[:,1], marker = '.', s = 30, color='white')\n","ax1.set_xlabel(r'$x_1$',fontsize = 16)\n","ax1.set_ylabel(r'$x_2$',fontsize = 16)\n","\n","# separate instances with classes 0 and 1 for the drawing\n","X0_tr, X1_tr = X_train[y_train == 0], X_train[y_train == 1]\n","\n","ax2.scatter(X0_tr[:,0],X0_tr[:,1], marker = 'o', color = color_class[0])\n","ax2.scatter(X1_tr[:,0],X1_tr[:,1], marker = '^', color = color_class[1])\n","ax2.set_title('Train set',fontsize = 16)\n","ax2.set_xlabel(r'$x_1$',fontsize = 16)\n","ax2.set_ylabel(r'$x_2$',fontsize = 16)\n","\n","Figure.show()"]},{"cell_type":"code","execution_count":null,"id":"265ec881-c0b6-4c5b-bb80-2ac471501bf9","metadata":{"id":"265ec881-c0b6-4c5b-bb80-2ac471501bf9"},"outputs":[],"source":["Figure, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14,5))\n","ax1.scatter(X[:,0],X[:,1], marker = 'o', s = 30)\n","ax1.scatter(X_test[:,0],X_test[:,1], marker = '.', s = 30, color='white')\n","ax1.set_xlabel(r'$x_1$',fontsize = 16)\n","ax1.set_ylabel(r'$x_2$',fontsize = 16)\n","\n","# separate instances with classes 0 and 1 for the drawing\n","X0_t, X1_t = X_test[y_test == 0], X_test[y_test == 1]\n","\n","\n","ax2.scatter(X0_t[:,0],X0_t[:,1], marker = 'o', color='red')\n","ax2.scatter(X1_t[:,0],X1_t[:,1], marker = '^', color='blue')\n","ax2.set_title('Test set',fontsize = 16)\n","ax2.set_xlabel(r'$x_1$',fontsize = 16)\n","ax2.set_ylabel(r'$x_2$',fontsize = 16)\n","\n","Figure.show()"]},{"cell_type":"markdown","id":"ebbf593a-0e11-4436-9517-9f6296d2ed3a","metadata":{"id":"ebbf593a-0e11-4436-9517-9f6296d2ed3a"},"source":["### Linear discriminant analysis (LDA)\n","\n","In a first step LDA is used to analyze the dataset in each of the two components $x_1$ and $x_2$ to see how the classes separate on each of them.\n","\n","In particular, we will  \n","* see how they spread on $x_1$ and $x_2$,\n","* calculate their cendroids\n","* Calculate the bivariate correlation and represent them\n"]},{"cell_type":"markdown","id":"631d04c7-0414-4f37-ba50-0160a3822435","metadata":{"id":"631d04c7-0414-4f37-ba50-0160a3822435"},"source":["### Train the model"]},{"cell_type":"code","execution_count":null,"id":"2d89e1f4-cb1b-4778-ad56-ca48c70b994c","metadata":{"id":"2d89e1f4-cb1b-4778-ad56-ca48c70b994c"},"outputs":[],"source":["# Here is the classifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"]},{"cell_type":"code","execution_count":null,"id":"fb861bda-3e76-4698-b8da-3fdcd41e1b23","metadata":{"id":"fb861bda-3e76-4698-b8da-3fdcd41e1b23"},"outputs":[],"source":["# create the model\n","lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n","model_lda = lda.fit(X_train, y_train)\n","\n","y_pred = model_lda.predict(X_test)\n","\n","print('Centroids:\\n',model_lda.means_)\n","print('Covariance matrix:\\n',model_lda.covariance_)"]},{"cell_type":"code","execution_count":null,"id":"026ffa26-8b62-4225-8f1b-7a542f39f5f2","metadata":{"id":"026ffa26-8b62-4225-8f1b-7a542f39f5f2"},"outputs":[],"source":["# Plot the centroids and covariance ellipses\n","\n","Figure, ax2 = plt.subplots(nrows=1, ncols=1, figsize=(7,5))\n","\n","# plot the dataset separated in two classes\n","#\n","X0_s, X1_s = X[y == 0], X[y == 1]\n","ax2.scatter(X0_s[:,0],X0_s[:,1], marker = '.', color = 'red', alpha=0.1)\n","ax2.scatter(X1_s[:,0],X1_s[:,1], marker = '^', color = 'blue', alpha=0.1)\n","ax2.set_xlabel(r'$x_1$',fontsize = 16)\n","ax2.set_ylabel(r'$x_2$',fontsize = 16)\n","\n","# Plot the centroids\n","#\n","ax2.plot(\n","   model_lda.means_[0][0],\n","   model_lda.means_[0][1],\n","   \"*\",\n","   color=\"yellow\",\n","   markersize=15,\n","   markeredgecolor=\"grey\",\n",")\n","ax2.plot(\n","   model_lda.means_[1][0],\n","   model_lda.means_[1][1],\n","   \"*\",\n","   color=\"yellow\",\n","   markersize=15,\n","   markeredgecolor=\"grey\",\n",")\n","\n","# The eigenvalues of the covatiance matrix are calculated\n","# Determine the pricipal vectors of the bivariates distributions\n","# This is similar to the principal component analysis\n","#\n","v, w = linalg.eigh(model_lda.covariance_)\n","\n","# For class 0\n","u = w[0] / linalg.norm(w[0])\n","angle = np.arctan(u[1] / u[0])\n","angle = 180 * angle / np.pi  # convert to degrees\n","\n","# For class 1\n","u2 = w[1] / linalg.norm(w[1])\n","angle = np.arctan(u2[1] / u2[0])\n","angle = 180 * angle / np.pi  # convert to degrees\n","\n","# fill the aera corresponding to a Gaussian inside 2 times the standard deviation\n","# This is a filled Ellipse\n","ell0 = Ellipse(\n","    lda.means_[0,:],\n","    2 * v[0] ** 0.5,\n","    2 * v[1] ** 0.5,\n","    angle = 90 + angle,\n","    facecolor='red',\n","    edgecolor=\"red\",\n","    linewidth=3,\n",")\n","\n","ell1 = Ellipse(\n","    lda.means_[1,:],\n","    2 * v[0] ** 0.5,\n","    2 * v[1] ** 0.5,\n","    angle = 90 + angle,\n","    facecolor='blue',\n","    edgecolor=\"blue\",\n","    linewidth=3,\n",")\n","\n","ell0.set_clip_box(ax2.bbox)\n","ell0.set_alpha(0.3)\n","ell1.set_clip_box(ax2.bbox)\n","ell1.set_alpha(0.3)\n","ax2.add_artist(ell0)\n","ax2.add_artist(ell1)\n","\n","#Plot the distribution on each axis\n","fact = 0.5\n","offs = -1\n","x =  np.linspace(-2.5,3,200)\n","y1 = fact*stats.norm.pdf(x, loc= model_lda.means_[0][0], scale=2*v[0]**0.5)\n","y2 = fact*stats.norm.pdf(x, loc= model_lda.means_[1][0], scale=2*v[0]**0.5)\n","\n","fact2 = 0.5\n","offs2 = -2.5\n","x2 =  np.linspace(-1,2,200)\n","y12 = fact2*stats.norm.pdf(x2, loc= model_lda.means_[0][1], scale=v[0]**0.5)\n","y22 = fact*stats.norm.pdf(x2, loc= model_lda.means_[1][1], scale=v[0]**0.5)\n","ax2.plot(x, offs+y1+y2, color='black', linestyle = 'dashed')\n","ax2.plot(x, offs+y1, color='red', alpha = 0.6)\n","ax2.plot(x, offs+y2, color='blue', alpha = 0.6)\n","\n","ax2.plot(offs2+y12+y22, x2, color='black', linestyle = 'dashed')\n","ax2.plot(offs2+y12, x2, color='red', alpha = 0.6)\n","ax2.plot(offs2+y22, x2, color='blue', alpha = 0.6)\n","#ax2.plot(x,offs+y1+y2,color='black',linestyle='-',alpha = 0.5)\n","\n","\n","#ax2.set_xticks(())\n","#ax2.set_yticks(())\n","\n","Figure.show()"]},{"cell_type":"markdown","id":"688647df-521d-4c6e-87c1-b1515b9539ad","metadata":{"tags":[],"id":"688647df-521d-4c6e-87c1-b1515b9539ad"},"source":["#### Analysis\n","* From the gaussian distributions used to represent the data, $x_1$ and $x_2$ are both representative of the $2$ classes\n","* The classes are more separated on axis $x_2$, we can imagine that the line of separation will be on this axix"]},{"cell_type":"markdown","id":"1df0fc85-d119-448c-9d49-b4d1f5e594ac","metadata":{"id":"1df0fc85-d119-448c-9d49-b4d1f5e594ac"},"source":["## Binary (2 classes) Classification"]},{"cell_type":"markdown","id":"86fe54e3-a78d-463a-aff6-24004e59cd38","metadata":{"id":"86fe54e3-a78d-463a-aff6-24004e59cd38"},"source":["### Logistic regression"]},{"cell_type":"code","execution_count":null,"id":"614b90fd-ca7f-4e94-9db0-052a427e106e","metadata":{"id":"614b90fd-ca7f-4e94-9db0-052a427e106e"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":null,"id":"b943faca-c2ad-4b41-a911-0b503c9fc186","metadata":{"id":"b943faca-c2ad-4b41-a911-0b503c9fc186"},"outputs":[],"source":["# Create the model for binary classification\n","# 'liblinear' and 'ovr' are chosen here for binary logistic regression.\n","# Please note: for multinomial logistic regression, you can use 'lbfgs' and 'multinomial'.\n","\n","logreg = LogisticRegression(solver='liblinear', multi_class='ovr')"]},{"cell_type":"code","execution_count":null,"id":"15604dcc-007d-4150-a618-99634532a224","metadata":{"id":"15604dcc-007d-4150-a618-99634532a224"},"outputs":[],"source":["logreg.fit(X_train, y_train)\n","y_pred = logreg.predict(X_test)\n","proba_log = logreg.predict_proba(X_test)\n","\n","Test_model_accuracy(y_pred, y_test)"]},{"cell_type":"markdown","id":"a68a44d5-c11d-4cc7-bde9-ba06ea21fe7c","metadata":{"id":"a68a44d5-c11d-4cc7-bde9-ba06ea21fe7c"},"source":["#### How does the algorithm affects the observation to a specific class ?"]},{"cell_type":"code","execution_count":null,"id":"42c36422-de25-4bc5-be5a-d6777b6a390d","metadata":{"id":"42c36422-de25-4bc5-be5a-d6777b6a390d"},"outputs":[],"source":["#figbar, (ax1,ax2) = plt.subplots(nrows=2, ncols = 1,figsize = (20,12))\n","barwidth = 0.5\n","figbar, ax1 = plt.subplots(nrows=1, ncols = 1,figsize = (20,5))\n","#ax1.tick_params(labelsize=18)\n","#ax2.tick_params(labelsize=18)\n","r1 = range(len(proba_log[:,0]))\n","r2 = [x + barwidth for x in r1]\n","\n","prob_sort=[x.tolist() for x in sorted(proba_log, key=itemgetter(0))]\n","probA=[x[0] for x in prob_sort]\n","probB=[x[1] for x in prob_sort]\n","\n","ax1.bar(r1, probA, width = barwidth, color=[color_class[0] for i in r1])\n","ax1.bar(r2, probB, width = barwidth, color=[color_class[1] for i in r1])\n","ax1.plot([0,len(proba_log[:,0])],[0.5,0.5])\n","ax1.set_title(r'Predicted probabilities (sorted)',fontsize = 20)\n","plt.xticks([r + barwidth / 2 for r in range(len(proba_log[:,0]))],[i for i in range(len(proba_log[:,0]),100)])\n","#ax2.set_title(r'Predicted probabilities of class $1$',fontsize = 20)\n","ax1.set_xlabel(r'test set points $X$',fontsize = 20)\n","#ax2.set_xlabel(r'test set points $X$',fontsize = 20)\n","\n","#plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","id":"99ff9aa4-0aef-47fc-afa6-d6b5979d67d7","metadata":{"id":"99ff9aa4-0aef-47fc-afa6-d6b5979d67d7"},"source":["#### Now draw the decision line"]},{"cell_type":"code","execution_count":null,"id":"f7434b9a-2817-4f3b-8cb9-322d83253cbb","metadata":{"tags":[],"id":"f7434b9a-2817-4f3b-8cb9-322d83253cbb"},"outputs":[],"source":["# Display\n","h = 0.01  # step size in the mesh\n","name = 'logistic regression'\n","Figure, (ax,ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (14,5))\n","ax.set_xlabel(r'$x_1$',fontsize = 16)\n","ax.set_ylabel(r'$x_2$',fontsize = 16)\n","ax2.set_xlabel(r'$x_1$',fontsize = 16)\n","ax2.set_ylabel(r'$x_2$',fontsize = 16)\n","ax2.set_xlim(xmin=-1,xmax=2)\n","ax2.set_ylim(ymin=0,ymax=1)\n","\n","# Retrieve the model parameters for the decision line.\n","b = logreg.intercept_[0]\n","w1, w2 = logreg.coef_.T\n","# Calculate the intercept and gradient of the decision boundary.\n","c = -b/w2\n","m = -w1/w2\n","\n","# Plot the data and the classification with the decision boundary.\n","xmin, xmax = -1, 2\n","ymin, ymax = 0, 1\n","xd = np.array([xmin, xmax])\n","yd = m*xd + c\n","ax2.plot(xd, yd, color = 'black', linewidth = 1, linestyle = '--', label = 'decision line')\n","\n","\n","DecisionBoundaryDisplay.from_estimator(\n","        logreg,\n","        X,\n","        cmap=cmap_light_b,\n","        alpha=0.3,\n","        ax=ax,\n","        response_method=\"predict\",\n","        plot_method=\"pcolormesh\",\n","        shading=\"auto\"\n","    )\n","\n","# Plot also  testing points\n","ax.scatter(X0_t[:,0],X0_t[:,1], marker = '.', color=color_class[0])\n","ax.scatter(X1_t[:,0],X1_t[:,1], marker = '^', color=color_class[1])\n","\n","ax.set_title(\"{} ({})\".format(name, 'ovr'))\n","\n","ax.text(\n","        0.8,\n","        0.1,\n","        \"Score: {:.2f}\".format(f1_score(y_test, y_pred)),\n","        size=15,\n","        ha=\"center\",\n","        va=\"center\",\n","        transform=ax.transAxes,\n",")\n","\n","rect=Rectangle((-1, 0), 3, 1,\n","    facecolor = None,\n","    fill = None,\n","    edgecolor = \"black\",\n","    linewidth=0.5)\n","ax.add_patch(rect)\n","\n","DecisionBoundaryDisplay.from_estimator(\n","        logreg,\n","        X,\n","        cmap=cmap_light_b,\n","        alpha=0.3,\n","        ax=ax2,\n","        response_method=\"predict\",\n","        plot_method=\"pcolormesh\",\n","        shading=\"auto\"\n","    )\n","\n","# Plot also  testing points\n","ax2.scatter(X0_t[:,0],X0_t[:,1], marker = '.', color='red')\n","ax2.scatter(X1_t[:,0],X1_t[:,1], marker = '^', color='blue')\n","ax2.set_title(\"Logistic regression: true test classes\")\n","ax2.legend(fontsize = 16)\n","Figure.show()"]},{"cell_type":"code","execution_count":null,"id":"aa135478-02cd-45a6-ab8e-f0005036e2cc","metadata":{"id":"aa135478-02cd-45a6-ab8e-f0005036e2cc"},"outputs":[],"source":["# Import some tools from Scikit-Learn\n","\n","# Metrix\n","\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score\n","\n","# Inspection tools\n","from sklearn.inspection import DecisionBoundaryDisplay"]},{"cell_type":"markdown","id":"6d473069-594c-4b6b-815d-c87808194da5","metadata":{"id":"6d473069-594c-4b6b-815d-c87808194da5"},"source":["### Suport Vector Machines (SVM)"]},{"cell_type":"code","execution_count":null,"id":"8ab8753f-8258-4c1a-bd2c-1b7cccc79190","metadata":{"id":"8ab8753f-8258-4c1a-bd2c-1b7cccc79190"},"outputs":[],"source":["from sklearn.svm import SVC"]},{"cell_type":"code","execution_count":null,"id":"cf0dc815-6d6b-4e93-b749-c490ec9bbec3","metadata":{"id":"cf0dc815-6d6b-4e93-b749-c490ec9bbec3"},"outputs":[],"source":["# Create and train the SVM model\n","svmlin = SVC(kernel='linear') # 'linear' kernel is used here.\n","svmlin.fit(X_train, y_train)\n","\n","# Make predictions and evaluate the model\n","y_pred = svmlin.predict(X_test)\n","\n","Test_model_accuracy (y_pred, y_test)"]},{"cell_type":"code","execution_count":null,"id":"d8d19f4d-7943-4be2-94f5-d3caaa4fcc9d","metadata":{"tags":[],"id":"d8d19f4d-7943-4be2-94f5-d3caaa4fcc9d"},"outputs":[],"source":["# Display\n","h = 0.01  # step size in the mesh\n","name = 'Suport Vector Machine'\n","Figure, ax = plt.subplots()\n","ax.set_xlabel(r'$x_1$',fontsize = 16)\n","ax.set_ylabel(r'$x_2$',fontsize = 16)\n","\n","DecisionBoundaryDisplay.from_estimator(\n","        svmlin,\n","        X,\n","        cmap=cmap_light_b,\n","        alpha=0.3,\n","        ax=ax,\n","        response_method=\"predict\",\n","        plot_method=\"pcolormesh\",\n","        shading=\"auto\",\n","    )\n","\n","# Plot also  testing points\n","#plt.scatter(X_test[:, 0], X_[:, 1], c=y, cmap=cmap_bold, edgecolor=\"k\", s=20)\n","ax.scatter(X0_t[:,0],X0_t[:,1], marker = '.', color='red')\n","ax.scatter(X1_t[:,0],X1_t[:,1], marker = '^', color='blue')\n","\n","plt.title(\"{} ({})\".format(name, \"linear\"))\n","plt.text(\n","        0.9,\n","        0.1,\n","        \"{:.2f}\".format(f1_score(y_test, y_pred)),\n","        size=15,\n","        ha=\"center\",\n","        va=\"center\",\n","        transform=plt.gca().transAxes,\n",")\n","\n","Figure.show()"]},{"cell_type":"markdown","id":"6b72653f-ea57-4051-af51-7e3cee10098d","metadata":{"id":"6b72653f-ea57-4051-af51-7e3cee10098d"},"source":["#### Checking the different SVM models:"]},{"cell_type":"code","execution_count":null,"id":"27338937-5ec1-4c84-98e7-bcf57beff983","metadata":{"id":"27338937-5ec1-4c84-98e7-bcf57beff983"},"outputs":[],"source":["# The list of possible kernels\n","#\n","kernels = ['linear', 'poly','rbf','sigmoid']\n","\n","svms=[]\n","predict_svms=[]\n","accuracy_svms = []\n","\n","# Create and train for each SVM model\n","#\n","for k in kernels:\n","    svm = SVC(kernel=k) # 'lbf' kernel is used here.\n","    svm.fit(X_train, y_train)\n","    svms.append(svm)\n","    # Make predictions and evaluate the model\n","    y_pred = svm.predict(X_test)\n","    predict_svms.append(y_pred)\n","    accuracy_svms.append(f1_score(y_pred, y_test))\n","\n","plt.plot(kernels,accuracy_svms)\n","plt.xticks(fontsize = 16)\n","plt.yticks(fontsize = 16)\n","plt.xlabel(r'Kernel',fontsize = 16)\n","plt.ylabel(r'accuracy',fontsize = 16)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"520284d6-6640-483f-9cfd-428090a036c0","metadata":{"tags":[],"id":"520284d6-6640-483f-9cfd-428090a036c0"},"outputs":[],"source":["# Display\n","h = 0.05  # step size in the mesh\n","name = 'Suport Vector Machine'\n","\n","nrows = 1\n","ncols = 4\n","Figure, axs = plt.subplots(nrows = nrows, ncols = ncols, figsize = (25,6))\n","for k, i in zip(kernels,range(len(kernels))):\n","    plt.sca(axs[i])\n","    axs[i].set_xlabel(r'$x_1$',fontsize = 20)\n","    axs[i].set_ylabel(r'$x_2$',fontsize = 20)\n","    axs[i].tick_params(labelsize=20)\n","\n","    DecisionBoundaryDisplay.from_estimator(\n","        svms[kernels.index(k)],\n","        X,\n","        cmap=cmap_light_b,\n","        alpha=0.8,\n","        ax=axs[i],\n","        response_method=\"predict\",\n","        plot_method=\"pcolormesh\",\n","        shading=\"auto\",\n","    )\n","\n","# Plot also  testing points\n","#plt.scatter(X_test[:, 0], X_[:, 1], c=y, cmap=cmap_bold, edgecolor=\"k\", s=20)\n","    axs[i].scatter(X0_t[:,0],X0_t[:,1], marker = '.', color='red')\n","    axs[i].scatter(X1_t[:,0],X1_t[:,1], marker = '^', color='blue')\n","\n","    axs[i].set_title(\"{} ({})\".format(name, k),fontsize=20)\n","    axs[i].text(\n","        0.9,\n","        0.1,\n","        \"{:.2f}\".format(accuracy_svms[kernels.index(k)]),\n","        size=15,\n","        ha=\"center\",\n","        va=\"center\",\n","        transform=plt.gca().transAxes,\n","    )\n","\n","plt.tight_layout()"]},{"cell_type":"markdown","id":"07787972-73e8-49de-b490-8181f284e9c1","metadata":{"id":"07787972-73e8-49de-b490-8181f284e9c1"},"source":["### $k$-Nearest Neighbors ($k$-NN)"]},{"cell_type":"code","execution_count":null,"id":"d3c56a2e-55fb-4121-b9b2-426c92b9f438","metadata":{"id":"d3c56a2e-55fb-4121-b9b2-426c92b9f438"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","#create the model classifier, the simplest one with 1 neighbor\n","#\n","n_neighbors = 1\n","knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n","\n","# train the model\n","knn.fit(X_train, y_train)\n","\n","# Test the modelknn_clf=KNeighborsClassifier()\n","y_pred = knn.predict(X_test)\n","Test_model_accuracy (y_pred, y_test)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"89580d21-fea5-41c6-9b42-1d5c22a66429","metadata":{"tags":[],"id":"89580d21-fea5-41c6-9b42-1d5c22a66429"},"outputs":[],"source":["# Display\n","h = 0.05  # step size in the mesh\n","name = 'k-NN'\n","Figure, ax = plt.subplots()\n","ax.set_xlabel(r'$x_1$',fontsize = 16)\n","ax.set_ylabel(r'$x_2$',fontsize = 16)\n","\n","DecisionBoundaryDisplay.from_estimator(\n","        knn,\n","        X,\n","        cmap=cmap_light_b,\n","        alpha=0.3,\n","        ax=ax,\n","        response_method=\"predict\",\n","        plot_method=\"pcolormesh\",\n","        shading=\"auto\",\n","    )\n","\n","# Plot also  test points according to their true class\n","ax.scatter(X0_t[:,0],X0_t[:,1], marker = '.', color='red')\n","ax.scatter(X1_t[:,0],X1_t[:,1], marker = '^', color='blue')\n","\n","plt.title(\"{} (k = {})\".format(name, n_neighbors))\n","plt.text(\n","        0.8,\n","        0.1,\n","        \"Score: {:.2f}\".format(f1_score(y_test, y_pred)),\n","        size=15,\n","        ha=\"center\",\n","        va=\"center\",\n","        transform=ax.transAxes,\n",")\n","\n","Figure.show()\n"]},{"cell_type":"markdown","id":"37a22733-0664-4410-8606-95dfafdd7a52","metadata":{"id":"37a22733-0664-4410-8606-95dfafdd7a52"},"source":["#### Analysis\n","* The decision line is close to the SVM model with the radial basis kernel (RBF) not too far from the dataset\n","* A closer look shows that probably with $k=1$ ($1$ neighbor) follows too closely the local environment of the training points: we find Class $1$ inside the region where we expect Class 0 points. **This is known as overfitting**\n","* $k=1$ does not contain enough information of the neighborhood of the points : this means that we have to find a better model"]},{"cell_type":"markdown","id":"b40351cb-aec5-4318-8d81-99796b955920","metadata":{"id":"b40351cb-aec5-4318-8d81-99796b955920"},"source":["### Model Selection"]},{"cell_type":"markdown","source":["Here we present a crude, yet comprehensive way of doing model selection.\n","\n","The goal is to find the best value of $k$ that give the highest accuracy score"],"metadata":{"id":"suFLg0-y-t2T"},"id":"suFLg0-y-t2T"},{"cell_type":"code","execution_count":null,"id":"49c32202-c9a8-48f8-907a-1f7e6434d9be","metadata":{"tags":[],"id":"49c32202-c9a8-48f8-907a-1f7e6434d9be"},"outputs":[],"source":["neighbors = np.arange(1, 30)\n","train_accuracy = np.empty(len(neighbors))\n","test_accuracy = np.empty(len(neighbors))\n","\n","# Loop over K values\n","for i, k in enumerate(neighbors):\n","    knn = KNeighborsClassifier(n_neighbors=k)\n","    knn.fit(X_train, y_train)\n","\n","    # Compute training and test data accuracy\n","#    train_accuracy[i] = knn.score(X_train, y_train)\n","    train_accuracy[i] = f1_score(y_train, knn.predict(X_train))\n","    test_accuracy[i] = f1_score(y_test, knn.predict(X_test))\n","\n","# Generate plot\n","plt.plot(neighbors, test_accuracy, label = 'Testing set Accuracy')\n","plt.plot(neighbors, train_accuracy, label = 'Training set Accuracy')\n","\n","plt.legend()\n","plt.xlabel('n_neighbors')\n","plt.ylabel('Accuracy')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"5c78da9e-a4f6-465c-9d7e-3b35e578cd93","metadata":{"id":"5c78da9e-a4f6-465c-9d7e-3b35e578cd93"},"outputs":[],"source":["# Select the model with the maximum accuracy and train it again\n","#\n","n_neighbors = np.argmax(test_accuracy)+1\n","knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n","knn.fit(X_train, y_train)\n","y_pred = knn.predict(X_test)"]},{"cell_type":"code","execution_count":null,"id":"5ceadf42-f9b8-4a41-b5aa-a78237244118","metadata":{"tags":[],"id":"5ceadf42-f9b8-4a41-b5aa-a78237244118"},"outputs":[],"source":["proba= knn.predict_proba(X_test)\n","\n","barwidth = 0.5\n","figbar, ax1 = plt.subplots(nrows=1, ncols = 1,figsize = (20,5))\n","#ax1.tick_params(labelsize=18)\n","#ax2.tick_params(labelsize=18)\n","\n","r1 = range(len(proba_log[:,0]))\n","r2 = [x + barwidth for x in r1]\n","\n","prob_sort=[x.tolist() for x in sorted(proba_log, key=itemgetter(0))]\n","probA=[x[0] for x in prob_sort]\n","probB=[x[1] for x in prob_sort]\n","\n","ax1.bar(r1, probA, width = barwidth, color=[color_class[0] for i in r1])\n","ax1.bar(r2, probB, width = barwidth, color=[color_class[1]for i in r1])\n","ax1.plot([0,len(proba_log[:,0])],[0.5,0.5])\n","ax1.set_title(r'Predicted probabilities (sorted)',fontsize = 20)\n","plt.xticks([r + barwidth / 2 for r in range(len(proba_log[:,0]))],[i for i in range(len(proba_log[:,0]),100)])\n","#ax2.set_title(r'Predicted probabilities of class $1$',fontsize = 20)\n","ax1.set_xlabel(r'test set points $X$',fontsize = 20)\n","\n","figbar.show()"]},{"cell_type":"code","execution_count":null,"id":"be05ad3f-51dd-4a40-9ab2-1bb5b3385204","metadata":{"tags":[],"id":"be05ad3f-51dd-4a40-9ab2-1bb5b3385204"},"outputs":[],"source":["# Display\n","h = 0.05  # step size in the mesh\n","name = 'k-NN'\n","Figure, (ax,ax2,ax3) = plt.subplots(nrows = 1, ncols = 3, figsize = (21,5))\n","ax.set_xlabel(r'$x_1$',fontsize = 16)\n","ax.set_ylabel(r'$x_2$',fontsize = 16)\n","\n","ax2.set_xlabel(r'$x_1$',fontsize = 16)\n","ax2.set_ylabel(r'$x_2$',fontsize = 16)\n","ax2.set_xlim(xmin=-1,xmax=2)\n","ax2.set_ylim(ymin=0,ymax=1)\n","\n","ax3.set_xlabel(r'$x_1$',fontsize = 16)\n","ax3.set_ylabel(r'$x_2$',fontsize = 16)\n","ax3.set_xlim(xmin=-1,xmax=2)\n","ax3.set_ylim(ymin=0,ymax=1)\n","\n","DecisionBoundaryDisplay.from_estimator(\n","        knn,\n","        X,\n","        cmap=cmap_light_b,\n","        alpha=0.3,\n","        ax=ax2,\n","        response_method=\"predict\",\n","        plot_method=\"pcolormesh\",\n","        shading=\"auto\",\n","    )\n","\n","ax2.set_title(\"{} (k = {}) predicted classes on the test\".format(name, n_neighbors))\n","ax2.scatter(X_test[:, 0], X_test[:, 1], c=y_pred, cmap=cmap1, edgecolor=\"k\", s=60)\n","ax2.text(\n","        0.8,\n","        0.1,\n","        \"score {:.2f}\".format(f1_score(y_test, y_pred)),\n","        size=15,\n","        ha=\"center\",\n","        va=\"center\",\n","        transform=ax2.transAxes,\n",")\n","\n","DecisionBoundaryDisplay.from_estimator(\n","        knn,\n","        X,\n","        cmap=cmap_light_b,\n","        alpha=0.3,\n","        ax=ax3,\n","        response_method=\"predict\",\n","        plot_method=\"pcolormesh\",\n","        shading=\"auto\",\n","    )\n","# Plot also testing points\n","#plt.scatter(X_test[:, 0], X_[:, 1], c=y, cmap=cmap_bold, edgecolor=\"k\", s=20)\n","\n","ax3.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cmap1, edgecolor=\"k\", s=60)\n","\n","ax3.set_title(\"{} (k = {}) true test classes\".format(name, n_neighbors))\n","\n","DecisionBoundaryDisplay.from_estimator(\n","        knn,\n","        X,\n","        cmap=cmap_light_b,\n","        alpha=0.3,\n","        ax=ax,\n","        response_method=\"predict\",\n","        plot_method=\"pcolormesh\",\n","        shading=\"auto\",\n","    )\n","\n","rect=Rectangle((-1, 0), 3, 1,\n","    facecolor = None,\n","    fill = None,\n","    edgecolor = \"black\",\n","    linewidth=0.5)\n","\n","ax.add_patch(rect)\n","\n","ax.set_title(\"Predicted probabilities of class 0\")\n","\n","# Plot also  testing points\n","#mycolors = cmap1(np.linspace(0,1,len(X_test)))\n","cm = ax.scatter(X_test[:,0],X_test[:,1], c = proba[:,1],cmap = cmap1)\n","Figure.colorbar(cm, ax=ax)\n","\n","Figure.show()"]},{"cell_type":"markdown","id":"91201609-8ecd-4d71-818a-2a7e532c2ce3","metadata":{"id":"91201609-8ecd-4d71-818a-2a7e532c2ce3"},"source":["## Generalizing to N Classes"]},{"cell_type":"markdown","source":["### Data Generation"],"metadata":{"id":"VUrPwr5wjhb8"},"id":"VUrPwr5wjhb8"},{"cell_type":"code","execution_count":null,"id":"5a47ef0b-1206-4521-a0fe-d3cec8c839ac","metadata":{"id":"5a47ef0b-1206-4521-a0fe-d3cec8c839ac"},"outputs":[],"source":["# test classification dataset\n","from collections import Counter\n","from sklearn.datasets import make_classification\n","\n","# define the random state\n","random_state = 1\n","\n","# define the number of classes\n","n_classes = 3\n","\n","# define dataset\n","Xm, ym = make_classification(n_samples=1000\n","                           , n_features=2\n","                           , n_informative=2\n","                           , n_redundant=0\n","                           , n_classes= n_classes\n","                           , n_clusters_per_class = 1\n","                           , class_sep = 1.7\n","                           , random_state=random_state)\n","# summarize the dataset\n","print(Xm.shape, ym.shape)\n","print(Counter(ym))"]},{"cell_type":"code","execution_count":null,"id":"8039176b-b895-4539-b046-824a42d38867","metadata":{"id":"8039176b-b895-4539-b046-824a42d38867"},"outputs":[],"source":["Figure, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14,5))\n","ax1.scatter(Xm[:,0],Xm[:,1])\n","ax1.set_xlabel(r'$x_1$',fontsize = 16)\n","ax1.set_ylabel(r'$x_2$',fontsize = 16)\n","\n","X0m_s, X1m_s, X2m_s, = Xm[ym == 0], Xm[ym == 1], Xm[ym == 2]\n","ax2.scatter(X0m_s[:,0],X0m_s[:,1], marker = '.', color = color_class[0], alpha=0.5)\n","ax2.scatter(X1m_s[:,0],X1m_s[:,1], marker = '^', color = color_class[1], alpha=0.5)\n","ax2.scatter(X2m_s[:,0],X2m_s[:,1], marker = '^', color = color_class[2], alpha=0.5)\n","ax2.set_xlabel(r'$x_1$',fontsize = 16)\n","ax2.set_ylabel(r'$x_2$',fontsize = 16)\n","plt.show()"]},{"cell_type":"markdown","id":"8a5bd447-0024-4be3-bec2-6be38c8830b9","metadata":{"id":"8a5bd447-0024-4be3-bec2-6be38c8830b9"},"source":["### Logistic regression"]},{"cell_type":"code","execution_count":null,"id":"7c8e67a6-2baf-4ef8-8f4b-7ddd5c352d72","metadata":{"id":"7c8e67a6-2baf-4ef8-8f4b-7ddd5c352d72"},"outputs":[],"source":["from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.inspection import DecisionBoundaryDisplay"]},{"cell_type":"code","execution_count":null,"id":"0537d899-be38-456b-9e29-77b3151fd4ad","metadata":{"tags":[],"id":"0537d899-be38-456b-9e29-77b3151fd4ad"},"outputs":[],"source":["# define the multinomial logistic regression model\n","mlogreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n","\n","# define the model evaluation procedure\n","cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n","\n","# evaluate the model and collect the scores\n","n_scores = cross_val_score(mlogreg, Xm, ym, scoring='accuracy', cv=cv, n_jobs=-1)\n","\n","# report the model performance\n","print('Mean Accuracy: %.3f (+/- %.3f)' % (mean(n_scores), std(n_scores)))"]},{"cell_type":"code","execution_count":null,"id":"3e5fc454-e404-48ce-9db1-d3801ca40130","metadata":{"id":"3e5fc454-e404-48ce-9db1-d3801ca40130"},"outputs":[],"source":["# split the dataset into a train set and a test set : usually 80% of the data in the training\n","Xm_train, Xm_test, ym_train, ym_test = train_test_split(Xm, ym, test_size=0.20, random_state=random_state)"]},{"cell_type":"code","execution_count":null,"id":"bb849a63-2c43-4e02-b67d-2866c28abac8","metadata":{"id":"bb849a63-2c43-4e02-b67d-2866c28abac8"},"outputs":[],"source":["mlogreg.fit(Xm_train, ym_train)\n","ym_pred = mlogreg.predict(Xm_test)\n","proba_log = mlogreg.predict_proba(Xm_test)\n","# separate instances with classes 0 and 1 for the drawing\n","X0m_tr, X1m_tr, X2m_tr = Xm_train[ym_train == 0], Xm_train[ym_train == 1], Xm_train[ym_train == 2]\n","X0m_t, X1m_t, X2m_t = Xm_test[ym_test == 0], Xm_test[ym_test == 1], Xm_test[ym_test == 2]\n"]},{"cell_type":"code","execution_count":null,"id":"1669d217-8475-4203-8a10-ecae9227dcad","metadata":{"id":"1669d217-8475-4203-8a10-ecae9227dcad"},"outputs":[],"source":["h = 0.05  # step size in the mesh\n","name = 'multiclass Logistic regressions'\n","Figure, ax = plt.subplots()\n","ax.set_xlabel(r'$x_1$',fontsize = 16)\n","ax.set_ylabel(r'$x_2$',fontsize = 16)\n","\n","DecisionBoundaryDisplay.from_estimator(\n","        mlogreg,\n","        Xm,\n","        cmap=cmap_light,\n","        alpha=0.3,\n","        ax=ax,\n","        response_method=\"predict\",\n","        plot_method=\"pcolormesh\",\n","        shading=\"auto\",\n","    )\n","\n","# Plot also  test points according to their true class\n","plt.scatter(Xm_test[:, 0], Xm_test[:, 1], c=ym_test, cmap=cmap_bold, edgecolor=\"k\", s=20)\n","\n","plt.title(\"{} (nb classes = {})\".format(name, n_classes))\n","plt.text(\n","        0.8,\n","        0.1,\n","        \"Score: {:.2f}\".format(mean(n_scores)),\n","        size=15,\n","        ha=\"center\",\n","        va=\"center\",\n","        transform=ax.transAxes,\n",")\n","\n","Figure.show()"]},{"cell_type":"code","execution_count":null,"id":"e1066e21-d0b5-46ce-9ac1-73dcb4904d0e","metadata":{"tags":[],"id":"e1066e21-d0b5-46ce-9ac1-73dcb4904d0e"},"outputs":[],"source":["# Choose a point and predict its class\n","point = [[-4, -4]]\n","point_class = mlogreg.predict(point)"]},{"cell_type":"code","execution_count":null,"id":"9f0eaa52-3472-4d82-86a4-7a10b94d7e28","metadata":{"tags":[],"id":"9f0eaa52-3472-4d82-86a4-7a10b94d7e28"},"outputs":[],"source":["Figure, ax = plt.subplots()\n","ax.set_xlabel(r'$x_1$',fontsize = 16)\n","ax.set_ylabel(r'$x_2$',fontsize = 16)\n","\n","DecisionBoundaryDisplay.from_estimator(\n","        mlogreg,\n","        Xm,\n","        cmap=cmap_light,\n","        alpha=0.3,\n","        ax=ax,\n","        response_method=\"predict\",\n","        plot_method=\"pcolormesh\",\n","        shading=\"auto\",\n","    )\n","\n","ax.scatter(point[0][0],point[0][1], marker = '*', s=400, c = color_class[int(point_class)], edgecolor=\"yellow\")\n","\n","Figure.show()"]},{"cell_type":"markdown","id":"71cf53f7-ffc8-42d0-ab90-cc506f59611f","metadata":{"id":"71cf53f7-ffc8-42d0-ab90-cc506f59611f"},"source":["### Support Vector Machines"]},{"cell_type":"code","execution_count":null,"id":"e0febb08-1d2c-4a7e-b427-a88e377080a9","metadata":{"id":"e0febb08-1d2c-4a7e-b427-a88e377080a9"},"outputs":[],"source":["kernels = ['linear', 'poly','rbf','sigmoid']\n","\n","svms=[]\n","predict_svms=[]\n","accuracy_svms = []\n","\n","# Create and train for each SVM model\n","#\n","for k in kernels:\n","    svm = SVC(kernel=k) # 'lbf' kernel is used here.\n","    svm.fit(Xm_train, ym_train)\n","    svms.append(svm)\n","    # Make predictions and evaluate the model\n","    ym_pred = svm.predict(Xm_test)\n","    predict_svms.append(ym_pred)\n","    n_scores = cross_val_score(svm, Xm, ym, scoring='accuracy', cv=cv, n_jobs=-1)\n","    accuracy_svms.append(mean(n_scores))\n","\n","plt.scatter(kernels,accuracy_svms)\n","plt.errorbar(kernels, accuracy_svms, yerr=std(n_scores), capsize=5)\n","plt.xticks(fontsize = 16)\n","plt.yticks(fontsize = 16)\n","plt.xlabel(r'Kernel',fontsize = 16)\n","plt.ylabel(r'accuracy',fontsize = 16)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"1c13d2d0-b33f-4e91-9943-d2df897eed0d","metadata":{"id":"1c13d2d0-b33f-4e91-9943-d2df897eed0d"},"outputs":[],"source":["# Display\n","h = 0.05  # step size in the mesh\n","name = 'Suport Vector Machine'\n","\n","nrows = 1\n","ncols = 4\n","Figure, axs = plt.subplots(nrows = nrows, ncols = ncols, figsize = (25,6))\n","for k, i in zip(kernels,range(len(kernels))):\n","    plt.sca(axs[i])\n","    axs[i].set_xlabel(r'$x_1$',fontsize = 20)\n","    axs[i].set_ylabel(r'$x_2$',fontsize = 20)\n","    axs[i].tick_params(labelsize=20)\n","\n","    DecisionBoundaryDisplay.from_estimator(\n","        svms[kernels.index(k)],\n","        Xm,\n","        cmap=cmap_light,\n","        alpha=0.3,\n","        ax=axs[i],\n","        response_method=\"predict\",\n","        plot_method=\"pcolormesh\",\n","        shading=\"auto\",\n","    )\n","\n","# Plot also  testing points\n","    axs[i].scatter(Xm_test[:, 0], Xm_test[:, 1], c=ym_pred, cmap=cmap_bold, edgecolor=\"k\", s=20)\n","    axs[i].set_title(\"{} ({})\".format(name, k),fontsize=20)\n","    axs[i].text(\n","        0.9,\n","        0.1,\n","        \"{:.2f}\".format(accuracy_svms[kernels.index(k)]),\n","        size=15,\n","        ha=\"center\",\n","        va=\"center\",\n","        transform=plt.gca().transAxes,\n","    )\n","\n","plt.tight_layout()"]},{"cell_type":"markdown","id":"641d75fe-05f8-4252-a63e-19720e43e828","metadata":{"id":"641d75fe-05f8-4252-a63e-19720e43e828"},"source":["### K-NN with $k=1$"]},{"cell_type":"code","execution_count":null,"id":"8f8aed5c-ecfa-47c5-975f-1ffb2b48c8b2","metadata":{"id":"8f8aed5c-ecfa-47c5-975f-1ffb2b48c8b2"},"outputs":[],"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","#create the model classifier, the simplest one with 1 neighbor\n","#\n","n_neighbors = 1\n","knn1 = KNeighborsClassifier(n_neighbors=n_neighbors)\n","\n","# train the model\n","knn1.fit(Xm_train, ym_train)\n","\n","# Test the modelknn_clf=KNeighborsClassifier()\n","ym_pred = knn1.predict(Xm_test)"]},{"cell_type":"code","execution_count":null,"id":"58b01dca-0968-47c4-860f-5e26626d136a","metadata":{"id":"58b01dca-0968-47c4-860f-5e26626d136a"},"outputs":[],"source":["# Display\n","h = 0.05  # step size in the mesh\n","name = 'k-NN'\n","Figure, ax = plt.subplots()\n","ax.set_xlabel(r'$x_1$',fontsize = 16)\n","ax.set_ylabel(r'$x_2$',fontsize = 16)\n","\n","DecisionBoundaryDisplay.from_estimator(\n","        knn1,\n","        Xm,\n","        cmap=cmap_light,\n","        alpha=0.3,\n","        ax=ax,\n","        response_method=\"predict\",\n","        plot_method=\"pcolormesh\",\n","        shading=\"auto\",\n","    )\n","\n","plt.scatter(Xm_test[:, 0], Xm_test[:, 1], c=ym_test, cmap=cmap_bold, edgecolor=\"k\", s=20)\n","plt.title(\"{} (k = {})\".format(name, n_neighbors))\n","plt.text(\n","        0.8,\n","        0.1,\n","        \"Score: {:.2f}\".format(f1_score(y_test, y_pred)),\n","        size=15,\n","        ha=\"center\",\n","        va=\"center\",\n","        transform=ax.transAxes,\n",")\n","Figure.show()\n"]},{"cell_type":"markdown","id":"fcf72cbd-436c-4525-b530-5793967b76e8","metadata":{"id":"fcf72cbd-436c-4525-b530-5793967b76e8"},"source":["## Exercise: make a svm classification with a dataset of 4 classes  "]},{"cell_type":"markdown","id":"58c181fb-eb34-4a7b-9a87-110f2a890579","metadata":{"id":"58c181fb-eb34-4a7b-9a87-110f2a890579"},"source":["Here is the dataset that you are going to work on.\n"]},{"cell_type":"code","execution_count":null,"id":"a94ab717-4650-4059-8cfe-7a99f12543d2","metadata":{"id":"a94ab717-4650-4059-8cfe-7a99f12543d2"},"outputs":[],"source":["# test classification dataset\n","from collections import Counter\n","from sklearn.datasets import make_classification\n","\n","# define the random state\n","random_state = 1\n","\n","# define the number of classes\n","n_classes = 4\n","\n","# define dataset\n","Xc, yc = make_classification(n_samples=3000\n","                           , n_features=2\n","                           , n_informative= 2\n","                           , n_redundant=0\n","                           , n_classes= n_classes\n","                           , n_clusters_per_class = 1\n","                           , class_sep = 1.7\n","                           , random_state=random_state)\n","# summarize the dataset\n","print(Xc.shape, yc.shape)\n","print(Counter(yc))\n","print(yc)"]},{"cell_type":"markdown","id":"f729b98b-b00e-4b58-8e40-5b1ac60580b3","metadata":{"id":"f729b98b-b00e-4b58-8e40-5b1ac60580b3"},"source":["Tasks:\n","1. Visualise the data, perform a train/test split\n","2. Train and evaluate the 4 different SMV models\n","3. Draw the predictions (d√©cision lines)\n","4. Which SVM model seems to be the most suitable for a classification ?"]},{"cell_type":"markdown","id":"d2e6993c-7d55-44c9-82e7-94015e00d215","metadata":{"id":"d2e6993c-7d55-44c9-82e7-94015e00d215"},"source":["## Soluction\n","\n","### Visualise the data"]},{"cell_type":"code","execution_count":null,"id":"f13bc4d9-50aa-4b92-9a9e-4c86481d79d3","metadata":{"id":"f13bc4d9-50aa-4b92-9a9e-4c86481d79d3"},"outputs":[],"source":["To be done by you..."]},{"cell_type":"markdown","id":"c240e032-997f-48ee-a7af-17a2e52ce6ca","metadata":{"id":"c240e032-997f-48ee-a7af-17a2e52ce6ca"},"source":["### Train-test split"]},{"cell_type":"code","execution_count":null,"id":"4b601046-2720-4932-880e-c6d1f763c41f","metadata":{"id":"4b601046-2720-4932-880e-c6d1f763c41f"},"outputs":[],"source":["To be done by you..."]},{"cell_type":"markdown","id":"90933a18-735f-4b31-a01e-b5aaadd8fd77","metadata":{"id":"90933a18-735f-4b31-a01e-b5aaadd8fd77"},"source":["### Train the models"]},{"cell_type":"code","execution_count":null,"id":"317e8ec1-e5d0-419b-a4c3-143d402fd479","metadata":{"id":"317e8ec1-e5d0-419b-a4c3-143d402fd479"},"outputs":[],"source":["To be done by you..."]},{"cell_type":"markdown","id":"bc563e3e-0e97-41c3-94a7-eb2e86d0223a","metadata":{"id":"bc563e3e-0e97-41c3-94a7-eb2e86d0223a"},"source":["### Visualize the predictions"]},{"cell_type":"code","execution_count":null,"id":"71c6ca54-ed3a-417f-a10c-b05ed5fafd59","metadata":{"id":"71c6ca54-ed3a-417f-a10c-b05ed5fafd59"},"outputs":[],"source":["To be done by you..."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[],"collapsed_sections":["Lnt-EmuOBFWP","0c0fd8ef-b949-4bbf-8c1e-e1656b3dc0cd","86fe54e3-a78d-463a-aff6-24004e59cd38","6d473069-594c-4b6b-815d-c87808194da5","07787972-73e8-49de-b490-8181f284e9c1","b40351cb-aec5-4318-8d81-99796b955920","VUrPwr5wjhb8","8a5bd447-0024-4be3-bec2-6be38c8830b9","71cf53f7-ffc8-42d0-ab90-cc506f59611f","641d75fe-05f8-4252-a63e-19720e43e828"]}},"nbformat":4,"nbformat_minor":5}