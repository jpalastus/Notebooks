{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#How to Build Machine Learning Exchange and Correlation Functionals for DFT\n",
        "\n",
        "Made by Jo√£o Paulo Almeida de Mendon√ßa"
      ],
      "metadata": {
        "id": "RndIZzmhHqvT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KquPEECNL1K8"
      },
      "source": [
        "## Basics of PYSCF\n",
        "\n",
        "For people that have some experience with quantum chemistry nomenclature and softwares, the main obstacle in PySCF is that its structured to be \"python friendly\". The philosophy behind PySCF is that you define a molecule (or cell) and a method (\"mean-field\" of \"post-mean-field\") object, that combined can be used to run the SCF itself.  \n",
        "\n",
        "Exemple - H$_2$O, 3-611G, PBE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tquuSt8lYxWK",
        "outputId": "46364354-db0a-4341-f26f-6ac5f8850dcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyscf in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: numpy!=1.16,!=1.17,>=1.13 in /usr/local/lib/python3.10/dist-packages (from pyscf) (1.22.4)\n",
            "Requirement already satisfied: scipy!=1.5.0,!=1.5.1 in /usr/local/lib/python3.10/dist-packages (from pyscf) (1.10.1)\n",
            "Requirement already satisfied: h5py>=2.7 in /usr/local/lib/python3.10/dist-packages (from pyscf) (3.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --prefer-binary --upgrade pyscf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVkUFdl79P2r",
        "outputId": "ff48809d-0b5b-439d-b35d-f7ef2385bd1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-76.00933224032994"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "##### A very straightforward exemple with minimal information\n",
        "from pyscf import gto\n",
        "from pyscf import scf\n",
        "\n",
        "#Basic Molecule geometry and proprieties parsing. More features are explained in https://pyscf.org/user/gto.html\n",
        "mol = gto.M(\n",
        "    atom = '''\n",
        "    O  0.000   0.000   0.000\n",
        "    H  0.000  -0.757   0.587\n",
        "    H  0.000   0.757   0.587 ''',\n",
        "    basis = '6-311g')\n",
        "\n",
        "#Exemple of a basic restricted Hartree--Fock calculation.\n",
        "#mf.kernel returns the total energy, nothing else should be printed with mf.verbose = 0\n",
        "mf = scf.RHF(mol)\n",
        "mf.verbose = 0\n",
        "mf.kernel()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### A similar exemple, now with few keywords added to demonstrate PySCF functionalities \n",
        "from pyscf import dft,gto,scf\n",
        "\n",
        "#Molecule Definition\n",
        "mol = gto.M(\n",
        "    atom = '''\n",
        "    O  0.000   0.000   0.000\n",
        "    H  0.000  -0.757   0.587\n",
        "    H  0.000   0.757   0.587 ''',\n",
        "    charge = 0,                  # -1 = one extra electron\n",
        "    spin = 0,                    # Number of unpared electrons (same as 2S) \n",
        "    output = 'output.out',       # Direct output from this molecule to a file \n",
        "    basis = '6-311g'             # Basis set used on the SCF process\n",
        "    )\n",
        "\n",
        "\n",
        "#Same molecule, but now with a different method, unrestricted DFT (PBE).\n",
        "mf = scf.UKS(mol).newton()        # .newton() activates second-order self-consistent field (SOSCF)\n",
        "mf = scf.addons.frac_occ(mf)      # Allow fractional orbital ocupation to help convergence\n",
        "\n",
        "mf.xc = 'PBE'                     # Functional PBE. Any functional in XCLib can be used\n",
        "mf.verbose = 4                    # Defines verbosity level. 0 = no output\n",
        "mf.conv_tol = 1e-10               # Energy convergence criteria, in Eh\n",
        "mf.max_cycle = 100                # Maximun allowed number of SCF cycles\n",
        "\n",
        "\n",
        "mf.chkfile = 'chkpoint.dat'       # Checkpoint file to restart calculations\n",
        "mf.init_guess = 'vsap'            # Strategy used for initial density guess\n",
        "#mf.init_guess = 'chkpoint.dat'   # Loading old ckeckpoint file\n",
        "\n",
        "\n",
        "#Runs the SCF\n",
        "mf.kernel()\n",
        "\n",
        "#Analyze the given SCF object: \n",
        "#    print orbital energies, occupancies; \n",
        "#    print orbital coefficients; \n",
        "#    Mulliken population analysis; \n",
        "#    Diople moment.\n",
        "results = mf.analyze()\n",
        "\n",
        "#This is how we can get forces from this calculation\n",
        "force = mf.nuc_grad_method().kernel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jez1OBST8uFF",
        "outputId": "82c115f9-4642-4101-c11e-d8677d886f29"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "overwrite output file: output.out\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Overwritten attributes  get_occ  of <class 'pyscf.soscf.newton_ah.newton.<locals>.SecondOrderUHF'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQiVF_IuGK48"
      },
      "source": [
        "Now, you can try to compute a particular system that you like. Maybe try to run something that has charges and different spin states. Maybe try to define a HF calculation? Or a small coupled cluster one? Check https://pyscf.org/quickstart.html or https://pyscf.org/user.html for more informations on how to do it.\n",
        "\n",
        "Be aware that maybe you will need to play first with low  values of mf.conv_tol and mf.max_cycle, to be able to do it in the tutorial time.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ajnohUbdGKk7"
      },
      "outputs": [],
      "source": [
        "from pyscf import dft,gto,scf\n",
        "\n",
        "#mol = gto.M(\n",
        "#    atom = '''\n",
        "#    XX  0.000   0.000   0.000''',\n",
        "#    basis = '...'\n",
        "#    )\n",
        "\n",
        "#mf = ...\n",
        "\n",
        "\n",
        "#mf.kernel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97XAXI9hMb_-"
      },
      "source": [
        "Lets do one more step before egoing to ML. This is how we use PySCF to run DFT calculations with a customized functional, hard-coded.\n",
        "\n",
        "`eval_xc` should be built to return the list [$ùúÄ_{XC}$,$v_{XC}$,$f_{XC}$,$k_{XC}$], i.e., $ùúÄ_{XC}$ and its first, second, and third derivatives respectively. In particular, $v_{XC}=(\\frac{dùúÄ_{XC}}{dœÅ},\\frac{dùúÄ_{XC}}{dŒ≥},\\frac{dùúÄ_{XC}}{d\\nabla^2œÅ},\\frac{dùúÄ_{XC}}{dœÑ})$. This shape ensures the compatibility of our functional with the rest of PySCF.\n",
        "\n",
        "To show how to customize a functional, we define a new functional that has the PBE correlation + PW86 exchange (for PW86 see https://doi.org/10.1103/physrevb.33.8800). Specifically, the PW86 exchange is here defined in terms of the reduced density gradients using the published parametrization by Perdew."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyWDqdoiAlfJ",
        "outputId": "03c3ae39-1ac0-431b-a069-a2af887bc24e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-63.629287665204714"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from pyscf import dft\n",
        "\n",
        "def eval_xc(xc_code, rho, spin=0, relativity=0, deriv=1, omega=None, verbose=None):\n",
        "    pi=3.1415926535897932384626433832795028841971\n",
        "    third=1.0/3.0\n",
        "    # A fictitious XC functional\n",
        "    # xc_code = \"LDA\", \"GGA\", \"meta-GGA\"\n",
        "    # SHAPE OF rho:      LDA - 1D array of shape (N) to store electron density, N being the number of integration grid points \n",
        "    #                    GGA - 2D array of shape (4,N) to store density and \"density derivatives\" for x,y,z components\n",
        "    #                    meta-GGA - can be a (6,N) (with_lapl=True) array where last two rows are \\nabla^2 rho and tau = 1/2(\\nabla f)^2\n",
        "    rho0, dx, dy, dz = rho[:4]\n",
        "    gamma = (dx**2 + dy**2 + dz**2)\n",
        "    \n",
        "    kf=(3*pi**2)**third*(rho0+1e-6)**third\n",
        "    s=(gamma)**0.5/(2*kf*(rho0+1e-6))\n",
        "    a=0.0864\n",
        "    b=14.0\n",
        "    c=0.2\n",
        "    m=1.0/15.0\n",
        "    par=(1.0+(a/m)*s**2+b*s**4+c*s**6)\n",
        "    Fx=par**m\n",
        "    chainrule=m*par**(m-1.0) * ((2.0*a/m)*s+4*b*s**3+6*c*s**5)\n",
        "    Fvrho   = chainrule * (4.0/3.0)*s/(rho0+1e-6)\n",
        "    #Fvgamma = chainrule *    0.5   *s/(gamma+1e-6)\n",
        "\n",
        "    # Getting original PBE Correlation and LDA Exchange\n",
        "    pbe_c = dft.libxc.eval_xc(',pbe', rho, spin, relativity, deriv, verbose)   # 'pbe,pbe' is a explicit way of choosing that both exchange\n",
        "    lda_x = dft.libxc.eval_xc('lda,',rho0, spin, relativity, deriv, verbose)   # and correlation will be done in the same way as 'PBE'.\n",
        "                                                                               # 'pbe,' or ',pbe' can be used to get the X and C separetly.\n",
        "                                                                               # The sintax is \"exchange,correlation\"\n",
        "      \n",
        "    \n",
        "\n",
        "    # Mixing PBE and the fictitious functional\n",
        "    exc = pbe_c[0] + Fx*lda_x[0]\n",
        "    vrho = pbe_c[1][0] + Fvrho*lda_x[1][0]\n",
        "    vgamma = pbe_c[1][1]\n",
        "    vlapl = None\n",
        "    vtau = None\n",
        "    vxc = (vrho, vgamma, vlapl, vtau)\n",
        "    fxc = None  # 2nd order functional derivative\n",
        "    kxc = None  # 3rd order functional derivative\n",
        "\n",
        "    return exc, vxc, fxc, kxc\n",
        "\n",
        "\n",
        "mol = gto.M(\n",
        "    atom = '''\n",
        "    O  0.000   0.000   0.000\n",
        "    H  0.000  -0.757   0.587\n",
        "    H  0.000   0.757   0.587 ''',\n",
        "    basis = '6-311g')\n",
        "\n",
        "mf = dft.RKS(mol)\n",
        "mf = mf.define_xc_(eval_xc, 'GGA', hyb=None)  # hyb is the amount of exact exchange to be used (HYBRID FUNCTIONAL)\n",
        "                                              # 'GGA' is the xctype, and defines the shape of rho passed to eval_xc\n",
        "mf.verbose = 0\n",
        "mf.guess='huckel'\n",
        "mf.kernel()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDKjfx8DNTY_"
      },
      "source": [
        "---\n",
        "## Crating a basic multilayer perceptron with TensorFlow\n",
        "\n",
        "\n",
        "```   \n",
        "          h - - - - h\n",
        "       /  h - - - - h  \\\n",
        "     /    h - - - - h    \\\n",
        "   /      h - - - - h      \\\n",
        "i         h - - - - h        \\\n",
        "                               \\\n",
        "i         .         .            \\\n",
        "          .         .              o\n",
        "i         .         .            /\n",
        "                               /\n",
        "i         h - - - - h        /\n",
        "   \\      h - - - - h      /\n",
        "     \\    h - - - - h    /\n",
        "       \\  h - - - - h  /\n",
        "          h - - - - h\n",
        "```\n",
        "- 4 input neurons\n",
        "- 100 neurons in hidden layer 1\n",
        "- 100 neurons in hidden layer 2\n",
        "- 1 output neuron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RSSKCeWRNHpI",
        "outputId": "8573f796-ffc2-426f-a9c4-cd9493acfa20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.8)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeRV5JzQN10j",
        "outputId": "8c4482dd-b704-483e-8665-dfa491fd3005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-131.07309   -51.745285  135.30573  -101.105156]] \t [[28.83809]]\n",
            "[[ 105.38672  -154.66153    55.68304   106.360176]] \t [[13.542726]]\n",
            "[[-158.54826    58.700634  -58.310425 -123.97181 ]] \t [[15.2679]]\n",
            "[[   5.223464   25.079119  -96.28534  -158.14421 ]] \t [[21.506754]]\n",
            "[[-61.575718   50.440155    5.0961313 100.081184 ]] \t [[5.5114546]]\n",
            "[[144.98987  -23.04728  -98.69745   15.573009]] \t [[2.3169525]]\n",
            "[[134.92712   18.2973    72.360146  19.26346 ]] \t [[2.3254583]]\n",
            "[[ 44.903133 144.73157   29.164146 -95.83941 ]] \t [[8.413941]]\n",
            "[[-163.37773    48.117264   96.65018    24.560034]] \t [[19.502247]]\n",
            "[[  58.209927  105.26288  -115.09255    96.38337 ]] \t [[3.9280396]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def nn_model(x_input, W1, b1, W2, b2, W3, b3):\n",
        "    x = tf.add(tf.matmul(tf.cast(x_input, tf.float32), W1), b1)      #\n",
        "    x = tf.nn.relu(x)                                                #\n",
        "    x = tf.add(tf.matmul(tf.cast(x, tf.float32), W2), b2)            # Bulding a multilayer perseptron using tf functions.\n",
        "    x = tf.nn.relu(x)                                                #  - add and matmul correspond to basic matrix addition and multiplication\n",
        "    x_output = tf.add(tf.matmul(x, W3), b3)                          #  - nn.relu is a build-in implementation of the activation function rELU(x)\n",
        "    return x_output                                                  #\n",
        "\n",
        "\n",
        "# weights connecting the input to the 1st hidden layer\n",
        "W1 = tf.random.normal([4, 100], stddev=0.1)\n",
        "b1 = tf.random.normal([100])\n",
        "# weights connecting the hidden layers \n",
        "W2 = tf.random.normal([100, 100], stddev=0.1)\n",
        "b2 = tf.random.normal([100])\n",
        "# weights connecting the 2nd hidden layer to the output layer\n",
        "W3 = tf.random.normal([100, 1], stddev=0.1)\n",
        "b3 = tf.random.normal([1])\n",
        "\n",
        "#Evaluating the ANN in random inputs, to showcase its usage. \n",
        "for i in range(10):\n",
        "  input=tf.random.normal([1,4], stddev=100.0)\n",
        "  print(input.numpy(),\"\\t\",nn_model(input, W1, b1, W2, b2, W3, b3).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxYvtuy5VSZ9"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Using a multilayer perceptron as functional\n",
        "\n",
        "\n",
        "Here, we do a simple exemple of using $ùúÄ_{XC}=F_{XC}*ùúÄ_{XC}^{PBE}$, where $F_{XC}$ is the output of a multilayer perceptron. The inputs are the values of density (œÅ) and the values of the gradients (Œ≥=|‚àáœÅ|), as the standard PBE.\n",
        "\n",
        "\n",
        "```   \n",
        "          h\n",
        "       /  h  \\\n",
        "     /    h    \\\n",
        "   /      h      \\\n",
        "œÅ         h        \\\n",
        "                     Fxc\n",
        "Œ≥         h        /\n",
        "   \\      h      /\n",
        "     \\    h    /\n",
        "       \\  h  /\n",
        "          h\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz6xNhmYVRPU",
        "outputId": "69f9bd3f-4aeb-435f-d50f-a95dfc03f785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "******** <class 'pyscf.dft.rks.RKS'> ********\n",
            "method = RKS\n",
            "initial guess = minao\n",
            "damping factor = 0\n",
            "level_shift factor = 0\n",
            "DIIS = <class 'pyscf.scf.diis.CDIIS'>\n",
            "diis_start_cycle = 1\n",
            "diis_space = 8\n",
            "SCF conv_tol = 1e-06\n",
            "SCF conv_tol_grad = None\n",
            "SCF max_cycles = 50\n",
            "direct_scf = True\n",
            "direct_scf_tol = 1e-13\n",
            "chkfile to save SCF result = /content/tmp8e8mzcrn\n",
            "max_memory 4000 MB (current use 575 MB)\n",
            "XC library pyscf.dft.libxc version 6.1.0\n",
            "    S. Lehtola, C. Steigemann, M. J.T. Oliveira, and M. A.L. Marques.,  SoftwareX 7, 1‚Äì5 (2018)\n",
            "XC functionals = LDA,VWN\n",
            "    P. A. M. Dirac.,  Math. Proc. Cambridge Philos. Soc. 26, 376 (1930)\n",
            "    F. Bloch.,  Z. Phys. 57, 545 (1929)\n",
            "    S. H. Vosko, L. Wilk, and M. Nusair.,  Can. J. Phys. 58, 1200 (1980)\n",
            "small_rho_cutoff = 1e-07\n",
            "Set gradient conv threshold to 0.001\n",
            "    CPU time for setting up grids      0.18 sec, wall time      0.17 sec\n",
            "nelec by numeric integration = 9.99145148631681\n",
            "    CPU time for vxc     16.85 sec, wall time     24.48 sec\n",
            "E1 = -121.69177431928165  Ecoul = 45.29044526257856  Exc = -4.097910068735687\n",
            "init E= -71.3109807076927\n",
            "cond(S) = 100.70804008167421\n",
            "    CPU time for initialize scf     17.18 sec, wall time     24.89 sec\n",
            "  HOMO = -0.0243017836834737  LUMO = 0.125317605956559\n",
            "  mo_energy =\n",
            "[-1.72612190e+01 -6.26311802e-01 -2.15150705e-01 -9.93516061e-02\n",
            " -2.43017837e-02  1.25317606e-01  1.98618564e-01  5.14717257e-01\n",
            "  5.76601762e-01  8.92142264e-01  8.93320528e-01  1.02188301e+00\n",
            "  1.34443416e+00  2.35366185e+00  2.39068666e+00  4.99423193e+00\n",
            "  5.11076247e+00  5.23701286e+00  5.10103855e+01]\n",
            "nelec by numeric integration = 10.000000080593793\n",
            "    CPU time for vxc     13.86 sec, wall time     15.43 sec\n",
            "E1 = -119.9179695054685  Ecoul = 43.3750664505612  Exc = -3.9469252331235776\n",
            "cycle= 1 E= -71.3015698702848  delta_E= 0.00941  |g|= 0.468  |ddm|= 1.24\n",
            "    CPU time for cycle= 1     13.92 sec, wall time     15.48 sec\n",
            "  HOMO = -0.107818968489437  LUMO = 0.0764843196360981\n",
            "  mo_energy =\n",
            "[-17.76200607  -0.78146445  -0.3425212   -0.15969     -0.10781897\n",
            "   0.07648432   0.15024404   0.46243257   0.49757941   0.82658198\n",
            "   0.84651077   0.94411701   1.24571183   2.24335148   2.28472631\n",
            "   4.80045546   4.90487566   5.01574979  50.49677846]\n",
            "nelec by numeric integration = 10.00000002133236\n",
            "    CPU time for vxc     12.34 sec, wall time     12.26 sec\n",
            "E1 = -122.92197636612147  Ecoul = 46.61050011021945  Exc = -4.13447529095457\n",
            "cycle= 2 E= -71.2576931291105  delta_E= 0.0439  |g|= 0.682  |ddm|= 0.539\n",
            "    CPU time for cycle= 2     12.45 sec, wall time     12.33 sec\n",
            "  HOMO = -0.00811080999682008  LUMO = 0.0982768875555504\n",
            "  mo_energy =\n",
            "[-1.74932271e+01 -6.80034120e-01 -2.63533150e-01 -6.81233963e-02\n",
            " -8.11081000e-03  9.82768876e-02  1.74324328e-01  4.93435689e-01\n",
            "  5.28382692e-01  9.00062615e-01  9.13552126e-01  1.00877748e+00\n",
            "  1.31921200e+00  2.27578928e+00  2.31578658e+00  4.95592286e+00\n",
            "  5.05761890e+00  5.16723816e+00  5.07602993e+01]\n",
            "nelec by numeric integration = 10.000000041838105\n",
            "    CPU time for vxc     12.35 sec, wall time     12.25 sec\n",
            "E1 = -120.45884729516243  Ecoul = 43.93660927379261  Exc = -3.989046531525921\n",
            "cycle= 3 E= -71.3230261351496  delta_E= -0.0653  |g|= 0.169  |ddm|= 0.475\n",
            "    CPU time for cycle= 3     12.46 sec, wall time     12.32 sec\n",
            "  HOMO = -0.0265943780514614  LUMO = 0.098881208081545\n",
            "  mo_energy =\n",
            "[-1.75247909e+01 -6.90807379e-01 -2.70627492e-01 -9.07574096e-02\n",
            " -2.65943781e-02  9.88812081e-02  1.73485251e-01  4.92424154e-01\n",
            "  5.32482619e-01  8.85525413e-01  8.95912610e-01  9.94695868e-01\n",
            "  1.30740597e+00  2.28699383e+00  2.32673157e+00  4.93100199e+00\n",
            "  5.03129432e+00  5.14255337e+00  5.07307427e+01]\n",
            "nelec by numeric integration = 10.000000045537487\n",
            "    CPU time for vxc     12.06 sec, wall time     11.98 sec\n",
            "E1 = -121.00891231394836  Ecoul = 44.50951040299124  Exc = -4.0175322551526635\n",
            "cycle= 4 E= -71.3286757483637  delta_E= -0.00565  |g|= 0.0117  |ddm|= 0.166\n",
            "    CPU time for cycle= 4     12.11 sec, wall time     12.02 sec\n",
            "  HOMO = -0.0250077183468108  LUMO = 0.0987728564567076\n",
            "  mo_energy =\n",
            "[-1.75231016e+01 -6.89481625e-01 -2.69807331e-01 -8.86693168e-02\n",
            " -2.50077183e-02  9.87728565e-02  1.73344318e-01  4.92620681e-01\n",
            "  5.32131327e-01  8.86721125e-01  8.97706084e-01  9.96048609e-01\n",
            "  1.30849399e+00  2.28624872e+00  2.32595281e+00  4.93254948e+00\n",
            "  5.03339083e+00  5.14434199e+00  5.07325564e+01]\n",
            "nelec by numeric integration = 10.000000045045159\n",
            "    CPU time for vxc     11.36 sec, wall time     11.35 sec\n",
            "E1 = -120.9706683194446  Ecoul = 44.46932585680984  Exc = -4.015626923506529\n",
            "cycle= 5 E= -71.3287109683952  delta_E= -3.52e-05  |g|= 0.00086  |ddm|= 0.0157\n",
            "    CPU time for cycle= 5     11.43 sec, wall time     11.40 sec\n",
            "  HOMO = -0.0251165229979187  LUMO = 0.0987325207543411\n",
            "  mo_energy =\n",
            "[-1.75231819e+01 -6.89650080e-01 -2.69902950e-01 -8.87128203e-02\n",
            " -2.51165230e-02  9.87325208e-02  1.73317615e-01  4.92585559e-01\n",
            "  5.32085139e-01  8.86635771e-01  8.97633645e-01  9.95961759e-01\n",
            "  1.30839862e+00  2.28620948e+00  2.32592013e+00  4.93243863e+00\n",
            "  5.03327177e+00  5.14422386e+00  5.07324811e+01]\n",
            "nelec by numeric integration = 10.000000045035705\n",
            "    CPU time for vxc     11.72 sec, wall time     11.72 sec\n",
            "E1 = -120.97305462271615  Ecoul = 44.47183821497537  Exc = -4.015753271177983\n",
            "cycle= 6 E= -71.3287112611727  delta_E= -2.93e-07  |g|= 5.22e-05  |ddm|= 0.00067\n",
            "    CPU time for cycle= 6     11.83 sec, wall time     11.81 sec\n",
            "  HOMO = -0.0251308279677794  LUMO = 0.0987327973280361\n",
            "  mo_energy =\n",
            "[-1.75232115e+01 -6.89656402e-01 -2.69909913e-01 -8.87352336e-02\n",
            " -2.51308280e-02  9.87327973e-02  1.73314642e-01  4.92583710e-01\n",
            "  5.32088497e-01  8.86624114e-01  8.97617704e-01  9.95948177e-01\n",
            "  1.30838880e+00  2.28622034e+00  2.32593038e+00  4.93241977e+00\n",
            "  5.03324996e+00  5.14420184e+00  5.07324518e+01]\n",
            "nelec by numeric integration = 10.000000045039044\n",
            "    CPU time for vxc     12.50 sec, wall time     12.43 sec\n",
            "E1 = -120.97350436994687  Ecoul = 44.47231170724119  Exc = -4.015777016199931\n",
            "Extra cycle  E= -71.3287112611595  delta_E= 1.32e-11  |g|= 0.000106  |ddm|= 0.000132\n",
            "    CPU time for scf_cycle    103.92 sec, wall time    112.71 sec\n",
            "    CPU time for SCF    103.95 sec, wall time    112.78 sec\n",
            "converged SCF energy = -71.3287112611595\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-71.3287112611595"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def nn_model(x_input, W1, b1, W2, b2):\n",
        "    x = tf.add(tf.matmul(tf.cast(x_input, tf.float32), W1), b1)\n",
        "    x = tf.nn.relu(x)\n",
        "    logits = tf.add(tf.matmul(x, W2), b2)\n",
        "    return logits\n",
        "\n",
        "#We are setting the parameters randomly. You should not expect to see any good results from this... \n",
        "#Also, the convergence may take forever. So... Be free to play with setting max cycles \n",
        "W1 = tf.random.normal([2, 10], stddev=0.01)\n",
        "b1 = tf.random.normal([10])\n",
        "W2 = tf.random.normal([10, 1], stddev=0.01)\n",
        "b2 = tf.random.normal([1])\n",
        "\n",
        "from pyscf import gto\n",
        "from pyscf import dft\n",
        "\n",
        "def eval_xc(xc_code, rho, spin, relativity=0, deriv=1, omega=None, verbose=None):\n",
        "    rho0, dx, dy, dz = rho[:4]\n",
        "    gamma = (dx**2 + dy**2 + dz**2)**.5\n",
        "\n",
        "    pbe_xc = dft.libxc.eval_xc('pbe,pbe', rho, spin, relativity, deriv, verbose)\n",
        "    exc = pbe_xc[0]\n",
        "    vrho = pbe_xc[1][0]\n",
        "    vgamma = pbe_xc[1][1]\n",
        "      \n",
        "    Fxc = [nn_model([[rho0[i],gamma[i]]],W1, b1, W2, b2).numpy()[0][0] for i in range(len(rho0))]\n",
        "    exc = Fxc * exc\n",
        "    vrho = Fxc * vrho\n",
        "    vgamma = Fxc * vgamma\n",
        "    vlapl = None\n",
        "    vtau = None\n",
        "    vxc = (vrho, vgamma, vlapl, vtau)\n",
        "    fxc = None \n",
        "    kxc = None \n",
        "    return exc, vxc, fxc, kxc\n",
        "\n",
        "mol = gto.M(\n",
        "    atom = '''\n",
        "    O  0.000   0.000   0.000\n",
        "    H  0.000  -0.757   0.587\n",
        "    H  0.000   0.757   0.587 ''',\n",
        "    basis = '6-311g')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "mf = dft.RKS(mol)\n",
        "mf = mf.define_xc_(eval_xc, 'GGA')\n",
        "mf.verbose = 5\n",
        "mf.conv_tol=1e-6\n",
        "mf.max_cycle = 50\n",
        "mf.kernel()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9WxuOppDkOv"
      },
      "source": [
        "\"Training\" is nothing more than an optimization of the parameters of our ANN to minimize the loss function. To do so, we must construct the loss function inside a proper function that can be passed to your optimization library of choice. In this case, some intricate casting and shaping arrangements probably will be used.\n",
        "\n",
        "I already did some \"hard\" work on training a very dummy functional on the Atomization Energy (AE) of water molecules only (a training set with a single molecule).  Here, we used $AE(H_2O)=E(H_2O)-E(H_2)-\\tfrac{1}{2}E(O_2)$. I performed a few non-gradient-based optimizations using PySwarms (https://pyswarms.readthedocs.io/en/latest/).\n",
        "\n",
        "Below, you can try to use some of those parameters (they are on the GitHub folder, maybe you will need to download and upload them to Colab by yourself...). To change between different sets, you can change \"h=np.load('param6.npy')\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrtzFCQxDjtd",
        "outputId": "87131172-98cd-458d-dcc8-5f7df84c12dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H2:\n",
            "  B3LYP:    -1.169858401694336\n",
            "  PBE:      -1.1630432931119747\n",
            "  ANN-PBE:  -0.5595747577335771\n",
            "-------------------------------------------------\n",
            "O2:\n",
            "  B3LYP:    -150.19872226867625\n",
            "  PBE:      -150.12050078128482\n",
            "  ANN-PBE:  -102.4605058537882\n",
            "-------------------------------------------------\n",
            "=================================================\n",
            "-------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from pyscf import gto, scf, dft\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def rolling(parameters): #This is here just to \"roll\" the vector stored on the parameter files to the correct shapes used on the ANN.\n",
        "\t###  w1\n",
        "\tstart=0\n",
        "\tend=start+2*10\n",
        "\tw1=parameters[start:end].reshape((2,10))\n",
        "\t###  b1\n",
        "\tstart=end\n",
        "\tend=start+10\n",
        "\tb1=parameters[start:end].reshape((10,))\n",
        "\t###  w2\n",
        "\tstart=end\n",
        "\tend=start+10*1\n",
        "\tw2=parameters[start:end].reshape((10,1))\n",
        "\t###  b2\n",
        "\tstart=end\n",
        "\tend=start+1\n",
        "\tb2=parameters[start:end].reshape((1,))\n",
        "\t\n",
        "\tif end != len(parameters):\n",
        "\t\tprint(\"Something is out of place... \")\n",
        "\t\tprint(\"end=\",end,\" but we expected it to be \", len(parameters))\n",
        "\t\texit()\n",
        "\t\n",
        "\treturn w1, b1, w2, b2\n",
        "\n",
        "def eval_xc(xc_code, rho, spin=0, relativity=0, deriv=1, omega=None, verbose=None):\n",
        "  rho0, dx, dy, dz = rho[:4]\n",
        "  gamma = (dx**2 + dy**2 + dz**2)**.5\n",
        "  G=[list(zip(rho0,gamma))]\n",
        "   \n",
        "  pbe_xc = dft.libxc.eval_xc('pbe,pbe', rho, spin, relativity, deriv, verbose)\n",
        "  exc = pbe_xc[0]\n",
        "  vrho = pbe_xc[1][0]\n",
        "  vgamma = pbe_xc[1][1]\n",
        "  \n",
        "  # LOADING THE SAVED PARAMETER!!!\n",
        "  h=np.load('param6.npy')\n",
        "  W1, b1, W2, b2 = rolling(h)\n",
        "\n",
        "  def nn_model(x_input, W1, b1, W2, b2):\n",
        "    log2=0.6931471805599453094172321214581765680755001343602552541206800094\n",
        "    x = tf.add(tf.matmul(tf.cast(x_input, tf.float32), W1), b1)\n",
        "    x = tf.nn.softplus(x)/log2\n",
        "    logits = tf.add(tf.matmul(x, W2), b2)\n",
        "    y = tf.nn.softplus(logits)/log2\n",
        "    return logits\n",
        "  fxc = nn_model(G, W1, b1, W2, b2).numpy()\n",
        "  exc = [fxc[0][i][0] * exc[i] for i in range(len(fxc[0]))]\n",
        "  vrho = [fxc[0][i][0] * vrho[i] for i in range(len(fxc[0]))]\n",
        "  vgamma = [fxc[0][i][0] * vgamma[i] for i in range(len(fxc[0]))]\n",
        "  vlapl = None\n",
        "  vtau = None\n",
        "  vxc = (vrho[0], vgamma[0], vlapl, vtau)\n",
        "\n",
        "  fxc = None  # 2nd order functional derivative\n",
        "  kxc = None  # 3rd order functional derivative\n",
        "  return exc, vxc, fxc, kxc\n",
        "\n",
        "\n",
        "\n",
        "# Computing H2 for AE\n",
        "mol = gto.M(\n",
        "    atom = '''\n",
        "    H        0.00000        0.00000   0.368583\n",
        "    H        0.00000        0.00000  -0.368583''',\n",
        "    basis = '6-311g')\n",
        "\n",
        "# We obtain the B3LYP value (reference) and density\n",
        "mf_mol = scf.RKS(mol)\n",
        "mf_mol.xc = 'B3LYP'\n",
        "mf_mol.verbose = 0\n",
        "mf_mol.max_cycle = 200\n",
        "mf_mol.init_guess = 'huckel'\n",
        "e_tot_reff=mf_mol.kernel()\n",
        "dmref = mf_mol.make_rdm1()\n",
        "\n",
        "# Compute total energy with trained functional for B3LYP density\n",
        "mf = dft.RKS(mol)\n",
        "mf = mf.define_xc_(eval_xc, 'GGA')\n",
        "mf.max_cycle = 0\n",
        "mf.verbose = 0\n",
        "e_tot_testf=mf.kernel(dm0=dmref)\n",
        "\n",
        "\n",
        "# Compute PBE total energy for B3LYP density\n",
        "mf = scf.RKS(mol)\n",
        "mf.xc = 'PBE'\n",
        "mf.verbose = 0\n",
        "mf.max_cycle = 0\n",
        "e_tot_PBE=mf.kernel(dm0=dmref)\n",
        "\n",
        "print(\"H2:\")\n",
        "print(\"  B3LYP:   \",e_tot_reff)\n",
        "e_tot_reff_H2=e_tot_reff*.5\n",
        "print(\"  PBE:     \",e_tot_PBE)\n",
        "e_tot_PBE_H2=e_tot_PBE*.5\n",
        "print(\"  ANN-PBE: \",e_tot_testf)\n",
        "e_tot_testf_H2=e_tot_testf*.5\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "## Computing O2 for AE\n",
        "mol = gto.M(\n",
        "    atom =''' \n",
        "            O        0.00000000       0.00000000       0.62297800\n",
        "            O        0.00000000       0.00000000      -0.62297800''',\n",
        "    basis = '6-311g')\n",
        "#B3LYP\n",
        "mf_mol = scf.RKS(mol)\n",
        "mf_mol.xc = 'B3LYP'\n",
        "mf_mol.verbose = 0\n",
        "mf_mol.max_cycle = 200\n",
        "mf_mol.init_guess = 'huckel'\n",
        "e_tot_reff=mf_mol.kernel()\n",
        "dmref = mf_mol.make_rdm1()\n",
        "#Trained functional\n",
        "mf = dft.RKS(mol)\n",
        "mf = mf.define_xc_(eval_xc, 'GGA')\n",
        "mf.max_cycle = 0\n",
        "mf.verbose = 0\n",
        "e_tot_testf=mf.kernel(dm0=dmref)\n",
        "#PBE\n",
        "mf = scf.RKS(mol)\n",
        "mf.xc = 'PBE'\n",
        "mf.verbose = 0\n",
        "mf.max_cycle = 0\n",
        "e_tot_PBE=mf.kernel(dm0=dmref)\n",
        "\n",
        "print(\"O2:\")\n",
        "print(\"  B3LYP:   \",e_tot_reff)\n",
        "e_tot_reff_O2=e_tot_reff*.5\n",
        "print(\"  PBE:     \",e_tot_PBE)\n",
        "e_tot_PBE_O2=e_tot_PBE*.5\n",
        "print(\"  ANN-PBE: \",e_tot_testf)\n",
        "e_tot_testf_O2=e_tot_testf*.5\n",
        "print(\"-------------------------------------------------\")\n",
        "print(\"=================================================\")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check those energies... They make any sence? Why the ones we predict are so far from the B3LYP and PBE ones? Is it an issue?"
      ],
      "metadata": {
        "id": "6ZpuGnv2DPNQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYB3UJ0QDa7X",
        "outputId": "fb1ca03b-101f-4926-a697-080d6b3e8c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------\n",
            "H2O (loss function):\n",
            " Err.ANN: 0.002064871581936245\n",
            " Err.PBE: 0.004229887915855102\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "H2O2:\n",
            " Err.ANN: 6.461784484201871e-05\n",
            " Err.PBE: 0.002372846581039312\n",
            "-------------------------------------------------\n",
            "-------------------------------------------------\n",
            "O3:\n",
            " Err.ANN: 0.031016918380743164\n",
            " Err.PBE: 0.021543374542233096\n",
            "-------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Error in H2O Atomization Energies (the one used for training)\n",
        "mol = gto.M(\n",
        "    atom = '''\n",
        "        O  0.000   0.000   0.000\n",
        "        H  0.000  -0.757   0.587\n",
        "        H  0.000   0.757   0.587 ''',\n",
        "    basis = '6-311g')\n",
        "\n",
        "mf_mol = scf.RKS(mol)\n",
        "mf_mol.xc = 'B3LYP'\n",
        "mf_mol.verbose = 0\n",
        "mf_mol.max_cycle = 200\n",
        "mf_mol.init_guess = 'huckel'\n",
        "e_tot_reff=mf_mol.kernel()\n",
        "dmref = mf_mol.make_rdm1()\n",
        "\n",
        "mf = dft.RKS(mol)\n",
        "mf = mf.define_xc_(eval_xc, 'GGA')\n",
        "mf.max_cycle = 0\n",
        "mf.verbose = 0\n",
        "e_tot_testf=mf.kernel(dm0=dmref)\n",
        "\n",
        "mf = scf.RKS(mol)\n",
        "mf.xc = 'PBE'\n",
        "mf.verbose = 0\n",
        "mf.max_cycle = 0\n",
        "e_tot_PBE=mf.kernel(dm0=dmref)\n",
        "\n",
        "print(\"-------------------------------------------------\")\n",
        "deltaE=abs((e_tot_reff-2.0*e_tot_reff_H2-e_tot_reff_O2)-(e_tot_testf-2.0*e_tot_testf_H2-e_tot_testf_O2))\n",
        "deltaEPBE=abs((e_tot_reff-2.0*e_tot_reff_H2-e_tot_reff_O2)-(e_tot_PBE-2.0*e_tot_PBE_H2-e_tot_PBE_O2))\n",
        "print(\"H2O (loss function):\")\n",
        "print(\" Err.ANN:\",deltaE)\n",
        "print(\" Err.PBE:\",deltaEPBE)\n",
        "print(\"-------------------------------------------------\")\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "\n",
        "# Error on AE for H2O2\n",
        "mol = gto.M(\n",
        "    atom = '''\n",
        "    O        0.00000000       0.73405800      -0.05275000\n",
        "    O        0.00000000      -0.73405800      -0.05275000\n",
        "    H        0.83954700       0.88075200       0.42200100\n",
        "    H       -0.83954700      -0.88075200       0.42200100''',\n",
        "    basis = '6-311g')\n",
        "\n",
        "mf_mol = scf.RKS(mol)\n",
        "mf_mol.xc = 'B3LYP'\n",
        "mf_mol.verbose = 0\n",
        "mf_mol.max_cycle = 200\n",
        "mf_mol.init_guess = 'huckel'\n",
        "e_tot_reff=mf_mol.kernel()\n",
        "dmref = mf_mol.make_rdm1()\n",
        "\n",
        "mf = dft.RKS(mol)\n",
        "mf = mf.define_xc_(eval_xc, 'GGA')\n",
        "mf.max_cycle = 0\n",
        "mf.verbose = 0\n",
        "e_tot_testf=mf.kernel(dm0=dmref)\n",
        "\n",
        "mf = scf.RKS(mol)\n",
        "mf.xc = 'PBE'\n",
        "mf.verbose = 0\n",
        "mf.max_cycle = 0\n",
        "e_tot_PBE=mf.kernel(dm0=dmref)\n",
        "\n",
        "print(\"-------------------------------------------------\")\n",
        "deltaE=abs((e_tot_reff-2.0*e_tot_reff_H2-2.0*e_tot_reff_O2)-(e_tot_testf-2.0*e_tot_testf_H2-2.0*e_tot_testf_O2))\n",
        "deltaEPBE=abs((e_tot_reff-2.0*e_tot_reff_H2-2.0*e_tot_reff_O2)-(e_tot_PBE-2.0*e_tot_PBE_H2-2.0*e_tot_PBE_O2))\n",
        "print(\"H2O2:\")\n",
        "print(\" Err.ANN:\",deltaE)\n",
        "print(\" Err.PBE:\",deltaEPBE)\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "# Error on AE for ozone (O3)\n",
        "mol = gto.M(\n",
        "    atom = '''\n",
        "    O        0.00000        1.10381  -0.228542\n",
        "    O        0.00000        0.00000   0.457084\n",
        "    O        0.00000       -1.10381  -0.228542''',\n",
        "    basis = '6-311g')\n",
        "\n",
        "mf_mol = scf.RKS(mol)\n",
        "mf_mol.xc = 'B3LYP'\n",
        "mf_mol.verbose = 0\n",
        "mf_mol.max_cycle = 200\n",
        "mf_mol.init_guess = 'huckel'\n",
        "e_tot_reff=mf_mol.kernel()\n",
        "dmref = mf_mol.make_rdm1()\n",
        "\n",
        "mf = dft.RKS(mol)\n",
        "mf = mf.define_xc_(eval_xc, 'GGA')\n",
        "mf.max_cycle = 0\n",
        "mf.verbose = 0\n",
        "e_tot_testf=mf.kernel(dm0=dmref)\n",
        "\n",
        "#PBE \n",
        "mf = scf.RKS(mol)\n",
        "mf.xc = 'PBE'\n",
        "mf.verbose = 0\n",
        "mf.max_cycle = 0\n",
        "e_tot_PBE=mf.kernel(dm0=dmref)\n",
        "\n",
        "print(\"-------------------------------------------------\")\n",
        "deltaE=abs((e_tot_reff-3.0*e_tot_reff_O2)-(e_tot_testf-3.0*e_tot_testf_O2))\n",
        "deltaEPBE=abs((e_tot_reff-3.0*e_tot_reff_O2)-(e_tot_PBE-3.0*e_tot_PBE_O2))\n",
        "print(\"O3:\")\n",
        "print(\" Err.ANN:\",deltaE)\n",
        "print(\" Err.PBE:\",deltaEPBE)\n",
        "print(\"-------------------------------------------------\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which molecules are predicted in a correct way and which are not? In which ones we improved over PBE?"
      ],
      "metadata": {
        "id": "modUpKMGDswu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "#Some things that you can try for yourself:\n",
        "\n",
        "\n",
        "\n",
        "1. Instead of correcting PBE, why not a Meta-GGA? Think on how the code needs to change.\n",
        "2. Check those parameters for self-consistent calculations. (SPOILER: They are bad. Maybe one can optimize everything using self-consistent energies... Maybe it can be you, in case you do the next suggestions.)\n",
        "3.   Implement the atomization energy of a small set of molecules as a function of the parameters (as a callable object). Maybe the structures can come from ase.collections (https://wiki.fysik.dtu.dk/ase/ase/collections.html#ase.collections.g2)\n",
        "4.   Send this loss function to a non-gradient-based optimization library and create your own functional. \n",
        "5.   Automate the validation for a set of molecules that extend on your training. \n",
        "\n"
      ],
      "metadata": {
        "id": "avzMlkm_EFsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#..."
      ],
      "metadata": {
        "id": "dz-ji60OEAIp"
      },
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}